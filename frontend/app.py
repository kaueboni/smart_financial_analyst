# frontend/app.py
import streamlit as st
import requests
import uuid
import time

# --- CONFIGURA√á√ïES DA APLICA√á√ÉO ---

# URL da nossa API FastAPI. O nome 'backend' √© resolvido pela rede interna do Docker.
API_URL = "http://backend:8000/invoke_agent"

# Configura√ß√£o da p√°gina do Streamlit
st.set_page_config(page_title="Smart Financial Analyst", layout="wide")

st.title("ü§ñ Smart Financial Analyst ")
st.markdown("""
Bem-vindo! Sou um agente de IA projetado para o ajudar a analisar dados financeiros.
Posso consultar dados de dividendos, buscar not√≠cias recentes na web e analisar relat√≥rios financeiros (PDFs) que foram carregados na minha base de conhecimento.
""")

# --- GEST√ÉO DA SESS√ÉO DE CONVERSA ---

# Inicializa o hist√≥rico de mensagens da UI se ainda n√£o existir
if "messages" not in st.session_state:
    st.session_state.messages = []

# Gera um ID de conversa √∫nico para esta sess√£o de navegador se ainda n√£o existir
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = str(uuid.uuid4())

# --- FUN√á√ÉO DE COMUNICA√á√ÉO COM O BACKEND ---

def call_agent_api(question: str, conv_id: str):
    """
    Envia a pergunta e o ID da conversa para a API do backend e retorna a resposta.
    """
    try:
        # Faz a requisi√ß√£o POST para o endpoint do nosso agente
        response = requests.post(
            API_URL, 
            json={"question": question, "conversation_id": conv_id},
            timeout=120 # Timeout de 2 minutos para permitir o processamento do LLM
        )
        # Levanta um erro para respostas com status de erro (4xx ou 5xx)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        # Retorna uma mensagem de erro se a comunica√ß√£o com o backend falhar
        return {"error": f"Erro de comunica√ß√£o com o backend: {e}"}

# --- CONSTRU√á√ÉO DA INTERFACE DE CHAT ---

# Exibe as mensagens do hist√≥rico na UI
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"],unsafe_allow_html=True)

# Aguarda por uma nova entrada do utilizador
if prompt := st.chat_input("Fa√ßa a sua pergunta..."):
    # Adiciona a mensagem do utilizador ao hist√≥rico da UI e exibe-a
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt,unsafe_allow_html=True)

    # Exibe a resposta do agente
    with st.chat_message("assistant"):
        # Mostra um spinner enquanto o agente est√° a "pensar"
        with st.spinner("O Smart Financial Analyst est√° a analisar... Por favor, aguarde."):
            # Chama a API do backend com a pergunta e o ID da sess√£o
            api_response = call_agent_api(prompt, st.session_state.conversation_id)

        # Verifica se a API retornou um erro
        if "error" in api_response:
            st.error(api_response["error"])
        else:
            # Exibe a resposta final do agente
            final_answer = api_response.get("final_answer", "N√£o foi poss√≠vel obter uma resposta.")
            st.markdown(final_answer,unsafe_allow_html=True)
            
            # Adiciona a resposta do agente ao hist√≥rico da UI
            st.session_state.messages.append({"role": "assistant", "content": final_answer})

            # (Opcional) Exibe os passos interm√©dios num expander para depura√ß√£o
            with st.expander("Ver o Racioc√≠nio do Agente"):
                steps = api_response.get("intermediate_steps", [])
                for step in steps:
                    st.write(f"**N√≥/Ferramenta:** `{step.get('node')}`")
                    st.write(f"**Detalhes:** {step.get('details') or step.get('status')}")
                    st.divider()
